{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"18IjUSe7KyaYJ7-axBKqs9bvaND9G6E8f","timestamp":1732708997580}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LinearRegression\n","from sklearn.metrics import mean_squared_error, r2_score\n","import matplotlib.pyplot as plt\n","import matplotlib.offsetbox as offsetbox\n","import tensorflow as tf\n","import random\n","from sklearn.preprocessing import StandardScaler, LabelEncoder\n","from tensorflow.keras.optimizers import Adam\n","\n","\n","def textbox(txt):\n","    plt.figure(figsize=(1,1))\n","    plt.gca().add_artist(offsetbox.AnchoredText(\"\\n\".join(txt), loc=\"center\",prop=dict(size=30)))\n","    plt.axis('off')\n","    plt.show()\n","    plt.close()"],"metadata":{"id":"CcY5Od5F10In","executionInfo":{"status":"ok","timestamp":1733044739416,"user_tz":360,"elapsed":9905,"user":{"displayName":"William Zhang","userId":"06004962365031563065"}}},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":["# 1. Build a deep learning model for the dataset"],"metadata":{"id":"61kSGxcC5myp"}},{"cell_type":"code","source":["#Data input\n","f_location = \"https://drive.google.com/file/d/1abp6Oc3XLvN7x2l2r1RHMjWNwoCTanLV/view?usp=sharing\"\n","data_raw = pd.read_csv('https://drive.google.com/uc?export=download&id=' + f_location.split('/')[-2]) #Convert to pandas DataFrames\n","\n","target_subjects = ['ABE', 'AE', 'BIOE', 'CEE', 'CS', 'CSE', 'ECE', 'ENG', 'IE', 'ME', 'MSE', 'NPRE', 'PHYS', 'SE', 'TAM', 'TE']\n","\n","grainger_data = data_raw[data_raw['Subject'].isin(target_subjects)].copy()\n","\n","#Data preprocessing\n","\n","# Calculate GPA using the provided formula\n","def calculate_gpa(row):\n","    grade_points = {\n","        # 'A+': 4.0, 'A': 4.0, 'A-': 3.7,\n","        # 'B+': 3.3, 'B': 3.0, 'B-': 2.7,\n","        # 'C+': 2.3, 'C': 2.0, 'C-': 1.7,\n","        # 'D+': 1.3, 'D': 1.0, 'D-': 0.7,\n","        # 'F': 0.0\n","        'A+': 4.00, 'A': 4.00, 'A-': 3.67,\n","        'B+': 3.33, 'B': 3.00, 'B-': 2.67,\n","        'C+': 2.33, 'C': 2.00, 'C-': 1.67,\n","        'D+': 1.33, 'D': 1.00, 'D-': 0.67,\n","        'F': 0.00\n","    }\n","\n","    total_points = 0\n","    total_grades = 0\n","\n","    for grade, points in grade_points.items():\n","        if grade in row:\n","            total_points += row[grade] * points\n","            total_grades += row[grade]\n","    if total_grades > 0:\n","        # make the dataset into a binary classification problem:\n","        # whether the average gpa of all students for this row is at least a B+\n","        return total_points / total_grades >= 3.33\n","    else:\n","        return np.nan\n","\n","#print(grainger_data)\n","# Add GPA column to the dataset\n","grainger_data['GPA'] = grainger_data.apply(calculate_gpa, axis=1)\n","grainger_data = grainger_data.drop(columns=['A+', 'A', 'A-', 'B+', 'B', 'B-', 'C+', 'C', 'C-', 'D+', 'D', 'D-', 'F', 'W'])\n","#print(grainger_data)\n","# Drop rows with NaN GPA values\n","grainger_data = grainger_data.dropna(subset=['GPA'])\n","\n","\n","\n","# Encode categorical features\n","label_encoders = {}\n","categorical_features = ['Subject', 'Course Title', 'Sched Type', 'Primary Instructor', 'Term', 'YearTerm']\n","for feature in categorical_features:\n","    le = LabelEncoder()\n","    grainger_data[feature] = le.fit_transform(grainger_data[feature])\n","    label_encoders[feature] = le\n","\n","print(le)\n","# Split data into training/validation and test sets based on year\n","train_val_data = grainger_data[grainger_data['Year'] < 2023]\n","test_data = grainger_data[grainger_data['Year'] == 2023]\n","\n","# Separate features and target variable\n","X_train_val = train_val_data.drop(columns=['GPA', 'Number', 'Year', 'Term',  'YearTerm'])\n","feature_names = X_train_val.columns.tolist()\n","y_train_val = train_val_data['GPA']\n","X_test = test_data.drop(columns=['GPA', 'Number', 'Year', 'Term',  'YearTerm'])\n","y_test = test_data['GPA']\n","\n","\n","print('test')\n","print(X_train_val)\n","print(y_train_val)\n","\n","# Standardize numerical features\n","scaler = StandardScaler()\n","X_train_val = scaler.fit_transform(X_train_val)\n","X_test = scaler.transform(X_test)\n","\n","# Split training and validation sets\n","X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.2, random_state=42)\n","\n","# Convert everything back to pd dataframe\n","X_train = pd.DataFrame(X_train, columns=categorical_features[:4])\n","X_val = pd.DataFrame(X_val, columns=categorical_features[:4])\n","X_test = pd.DataFrame(X_test, columns=categorical_features[:4])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Od3t8eHT4gYg","executionInfo":{"status":"ok","timestamp":1733044746530,"user_tz":360,"elapsed":7124,"user":{"displayName":"William Zhang","userId":"06004962365031563065"}},"outputId":"ff2ac596-1b70-478e-be1a-5c7e7aa01167"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["LabelEncoder()\n","test\n","       Subject  Course Title  Sched Type  Primary Instructor\n","2262         0           491           5                 105\n","2263         0           228           4                1147\n","2264         0           766           8                 246\n","2265         0           128           5                 977\n","2266         0           342           4                1118\n","...        ...           ...         ...                 ...\n","69030       11           975           5                 447\n","69031       11           973           5                 376\n","69066       13           550           5                 769\n","69067       13           554           4                 809\n","69068       13           551           5                 559\n","\n","[9914 rows x 4 columns]\n","2262      True\n","2263      True\n","2264      True\n","2265     False\n","2266      True\n","         ...  \n","69030    False\n","69031    False\n","69066    False\n","69067    False\n","69068    False\n","Name: GPA, Length: 9914, dtype: bool\n"]}]},{"cell_type":"code","source":["from tensorflow.keras.optimizers.schedules import LearningRateSchedule\n","from tensorflow.keras.layers import BatchNormalization, Dropout, Dense\n","\n","import tensorflow as tf\n","\n","# Custom LearningRateSchedule to adjust learning rate based on epoch\n","class StepLearningRate(LearningRateSchedule):\n","    def __init__(self, initial_lr, drop_factor, step_size):\n","        self.initial_lr = initial_lr  # Initial Learning Rate\n","        self.drop_factor = drop_factor\n","        self.step_size = step_size  # Adjust the learning rate every `step_size` epochs\n","        self.epoch = 0\n","\n","    def __call__(self, step):\n","        # Calculate the learning rate based on the epoch (decaying every `step_size` epochs)\n","        current_lr = self.initial_lr * (self.drop_factor ** (self.epoch // self.step_size))\n","        return tf.cast(current_lr, tf.float32)\n","\n","    # Update the epoch count at the end of each epoch\n","    def update_epoch(self, epoch):\n","        self.epoch = epoch\n","\n","# Create a StepLearningRate scheduler\n","initial_lr = 0.01\n","drop_factor = 0.5\n","step_size = 10\n","lr_schedule = StepLearningRate(initial_lr, drop_factor, step_size)\n","\n","# Custom callback to update the epoch and print the learning rate\n","class UpdateEpochCallback(tf.keras.callbacks.Callback):\n","    def __init__(self, lr_schedule):\n","        super(UpdateEpochCallback, self).__init__()\n","        self.lr_schedule = lr_schedule\n","\n","    def on_epoch_begin(self, epoch, logs=None):\n","        # update current epoch\n","        self.lr_schedule.update_epoch(epoch)\n","        # print current learning rate\n","        lr = tf.keras.backend.get_value(self.model.optimizer.learning_rate)\n","        print(f\"\\nEpoch {epoch + 1}: Learning rate is {lr:.6f}\")\n","\n","# Construct Model\n","model = tf.keras.Sequential([\n","    Dense(256, activation='relu', input_shape=(X_train.shape[1],)),\n","    BatchNormalization(),\n","    Dropout(0.1),\n","\n","    Dense(158, activation='relu'),\n","    BatchNormalization(),\n","    Dropout(0.1),\n","\n","    Dense(64, activation='relu'),\n","    BatchNormalization(),\n","    Dropout(0.1),\n","\n","    Dense(32, activation='relu'),\n","    BatchNormalization(),\n","    Dropout(0.1),\n","\n","    Dense(1, activation=\"sigmoid\")\n","])\n","\n","# Compile the model\n","optimizer = Adam(learning_rate=lr_schedule)  # Use the custom scheduler\n","model.compile(optimizer=optimizer, loss=tf.keras.losses.BinaryCrossentropy())\n","\n","# Initialize the callback\n","update_epoch_callback = UpdateEpochCallback(lr_schedule)\n","\n","# Train the model\n","history = model.fit(\n","    X_train, y_train,\n","    validation_data=(X_val, y_val),\n","    epochs=150,\n","    batch_size=32,\n","    verbose=1,\n","    callbacks=[update_epoch_callback]\n",")\n","\n","# Test the model\n","test_loss = model.evaluate(X_test, y_test, verbose=0)\n","print(f\"Test Loss: {test_loss}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fBRJf8gI7t_q","outputId":"825b2ef0-c9ea-471f-a249-ceab5b1f983d","executionInfo":{"status":"ok","timestamp":1733044975228,"user_tz":360,"elapsed":228700,"user":{"displayName":"William Zhang","userId":"06004962365031563065"}}},"execution_count":3,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\n","Epoch 1: Learning rate is 0.010000\n","Epoch 1/150\n","\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - loss: 0.7131 - val_loss: 0.6716\n","\n","Epoch 2: Learning rate is 0.010000\n","Epoch 2/150\n","\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.6754 - val_loss: 0.6564\n","\n","Epoch 3: Learning rate is 0.010000\n","Epoch 3/150\n","\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.6635 - val_loss: 0.6415\n","\n","Epoch 4: Learning rate is 0.010000\n","Epoch 4/150\n","\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.6504 - val_loss: 0.6308\n","\n","Epoch 5: Learning rate is 0.010000\n","Epoch 5/150\n","\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.6402 - val_loss: 0.6276\n","\n","Epoch 6: Learning rate is 0.010000\n","Epoch 6/150\n","\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.6417 - val_loss: 0.6129\n","\n","Epoch 7: Learning rate is 0.010000\n","Epoch 7/150\n","\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.6396 - val_loss: 0.6427\n","\n","Epoch 8: Learning rate is 0.010000\n","Epoch 8/150\n","\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.6348 - val_loss: 0.6234\n","\n","Epoch 9: Learning rate is 0.010000\n","Epoch 9/150\n","\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.6310 - val_loss: 0.6257\n","\n","Epoch 10: Learning rate is 0.010000\n","Epoch 10/150\n","\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.6324 - val_loss: 0.6188\n","\n","Epoch 11: Learning rate is 0.005000\n","Epoch 11/150\n","\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.6252 - val_loss: 0.6218\n","\n","Epoch 12: Learning rate is 0.005000\n","Epoch 12/150\n","\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.6334 - val_loss: 0.6271\n","\n","Epoch 13: Learning rate is 0.005000\n","Epoch 13/150\n","\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.6319 - val_loss: 0.6084\n","\n","Epoch 14: Learning rate is 0.005000\n","Epoch 14/150\n","\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.6268 - val_loss: 0.6068\n","\n","Epoch 15: Learning rate is 0.005000\n","Epoch 15/150\n","\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.6288 - val_loss: 0.6121\n","\n","Epoch 16: Learning rate is 0.005000\n","Epoch 16/150\n","\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.6183 - val_loss: 0.6173\n","\n","Epoch 17: Learning rate is 0.005000\n","Epoch 17/150\n","\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.6196 - val_loss: 0.6141\n","\n","Epoch 18: Learning rate is 0.005000\n","Epoch 18/150\n","\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.6210 - val_loss: 0.6017\n","\n","Epoch 19: Learning rate is 0.005000\n","Epoch 19/150\n","\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.6225 - val_loss: 0.6149\n","\n","Epoch 20: Learning rate is 0.005000\n","Epoch 20/150\n","\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.6188 - val_loss: 0.6079\n","\n","Epoch 21: Learning rate is 0.002500\n","Epoch 21/150\n","\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.6231 - val_loss: 0.5962\n","\n","Epoch 22: Learning rate is 0.002500\n","Epoch 22/150\n","\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.6122 - val_loss: 0.6003\n","\n","Epoch 23: Learning rate is 0.002500\n","Epoch 23/150\n","\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.6086 - val_loss: 0.6142\n","\n","Epoch 24: Learning rate is 0.002500\n","Epoch 24/150\n","\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.6222 - val_loss: 0.6042\n","\n","Epoch 25: Learning rate is 0.002500\n","Epoch 25/150\n","\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.6154 - val_loss: 0.6164\n","\n","Epoch 26: Learning rate is 0.002500\n","Epoch 26/150\n","\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.6141 - val_loss: 0.6029\n","\n","Epoch 27: Learning rate is 0.002500\n","Epoch 27/150\n","\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.6027 - val_loss: 0.5926\n","\n","Epoch 28: Learning rate is 0.002500\n","Epoch 28/150\n","\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.6154 - val_loss: 0.6031\n","\n","Epoch 29: Learning rate is 0.002500\n","Epoch 29/150\n","\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.6036 - val_loss: 0.6000\n","\n","Epoch 30: Learning rate is 0.002500\n","Epoch 30/150\n","\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.6080 - val_loss: 0.6071\n","\n","Epoch 31: Learning rate is 0.001250\n","Epoch 31/150\n","\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.6110 - val_loss: 0.6073\n","\n","Epoch 32: Learning rate is 0.001250\n","Epoch 32/150\n","\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.6124 - val_loss: 0.5867\n","\n","Epoch 33: Learning rate is 0.001250\n","Epoch 33/150\n","\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.6044 - val_loss: 0.5876\n","\n","Epoch 34: Learning rate is 0.001250\n","Epoch 34/150\n","\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.6017 - val_loss: 0.5992\n","\n","Epoch 35: Learning rate is 0.001250\n","Epoch 35/150\n","\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.6060 - val_loss: 0.5907\n","\n","Epoch 36: Learning rate is 0.001250\n","Epoch 36/150\n","\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.6015 - val_loss: 0.5913\n","\n","Epoch 37: Learning rate is 0.001250\n","Epoch 37/150\n","\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.6039 - val_loss: 0.6011\n","\n","Epoch 38: Learning rate is 0.001250\n","Epoch 38/150\n","\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.6104 - val_loss: 0.5885\n","\n","Epoch 39: Learning rate is 0.001250\n","Epoch 39/150\n","\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.5979 - val_loss: 0.5987\n","\n","Epoch 40: Learning rate is 0.001250\n","Epoch 40/150\n","\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.6079 - val_loss: 0.5908\n","\n","Epoch 41: Learning rate is 0.000625\n","Epoch 41/150\n","\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.6150 - val_loss: 0.6179\n","\n","Epoch 42: Learning rate is 0.000625\n","Epoch 42/150\n","\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.6008 - val_loss: 0.5828\n","\n","Epoch 43: Learning rate is 0.000625\n","Epoch 43/150\n","\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.6060 - val_loss: 0.5772\n","\n","Epoch 44: Learning rate is 0.000625\n","Epoch 44/150\n","\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.5961 - val_loss: 0.5911\n","\n","Epoch 45: Learning rate is 0.000625\n","Epoch 45/150\n","\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.5938 - val_loss: 0.5845\n","\n","Epoch 46: Learning rate is 0.000625\n","Epoch 46/150\n","\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.5914 - val_loss: 0.5792\n","\n","Epoch 47: Learning rate is 0.000625\n","Epoch 47/150\n","\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.5976 - val_loss: 0.5812\n","\n","Epoch 48: Learning rate is 0.000625\n","Epoch 48/150\n","\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.5892 - val_loss: 0.5845\n","\n","Epoch 49: Learning rate is 0.000625\n","Epoch 49/150\n","\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.5998 - val_loss: 0.5790\n","\n","Epoch 50: Learning rate is 0.000625\n","Epoch 50/150\n","\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.5946 - val_loss: 0.5751\n","\n","Epoch 51: Learning rate is 0.000312\n","Epoch 51/150\n","\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.5933 - val_loss: 0.5946\n","\n","Epoch 52: Learning rate is 0.000312\n","Epoch 52/150\n","\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.5910 - val_loss: 0.5823\n","\n","Epoch 53: Learning rate is 0.000312\n","Epoch 53/150\n","\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.5910 - val_loss: 0.5780\n","\n","Epoch 54: Learning rate is 0.000312\n","Epoch 54/150\n","\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.5856 - val_loss: 0.5745\n","\n","Epoch 55: Learning rate is 0.000312\n","Epoch 55/150\n","\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.5983 - val_loss: 0.5687\n","\n","Epoch 56: Learning rate is 0.000312\n","Epoch 56/150\n","\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.5863 - val_loss: 0.5725\n","\n","Epoch 57: Learning rate is 0.000312\n","Epoch 57/150\n","\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.5863 - val_loss: 0.5708\n","\n","Epoch 58: Learning rate is 0.000312\n","Epoch 58/150\n","\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.5850 - val_loss: 0.5689\n","\n","Epoch 59: Learning rate is 0.000312\n","Epoch 59/150\n","\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.5781 - val_loss: 0.5871\n","\n","Epoch 60: Learning rate is 0.000312\n","Epoch 60/150\n","\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.5801 - val_loss: 0.5951\n","\n","Epoch 61: Learning rate is 0.000156\n","Epoch 61/150\n","\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.5813 - val_loss: 0.5729\n","\n","Epoch 62: Learning rate is 0.000156\n","Epoch 62/150\n","\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.5847 - val_loss: 0.5631\n","\n","Epoch 63: Learning rate is 0.000156\n","Epoch 63/150\n","\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.5923 - val_loss: 0.5710\n","\n","Epoch 64: Learning rate is 0.000156\n","Epoch 64/150\n","\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.5866 - val_loss: 0.5762\n","\n","Epoch 65: Learning rate is 0.000156\n","Epoch 65/150\n","\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.5855 - val_loss: 0.5834\n","\n","Epoch 66: Learning rate is 0.000156\n","Epoch 66/150\n","\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.5882 - val_loss: 0.5629\n","\n","Epoch 67: Learning rate is 0.000156\n","Epoch 67/150\n","\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.5859 - val_loss: 0.5690\n","\n","Epoch 68: Learning rate is 0.000156\n","Epoch 68/150\n","\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.5788 - val_loss: 0.5866\n","\n","Epoch 69: Learning rate is 0.000156\n","Epoch 69/150\n","\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.5830 - val_loss: 0.5801\n","\n","Epoch 70: Learning rate is 0.000156\n","Epoch 70/150\n","\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.5765 - val_loss: 0.5755\n","\n","Epoch 71: Learning rate is 0.000078\n","Epoch 71/150\n","\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.5759 - val_loss: 0.5661\n","\n","Epoch 72: Learning rate is 0.000078\n","Epoch 72/150\n","\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.5750 - val_loss: 0.5753\n","\n","Epoch 73: Learning rate is 0.000078\n","Epoch 73/150\n","\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.5744 - val_loss: 0.5710\n","\n","Epoch 74: Learning rate is 0.000078\n","Epoch 74/150\n","\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.5745 - val_loss: 0.5707\n","\n","Epoch 75: Learning rate is 0.000078\n","Epoch 75/150\n","\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.5902 - val_loss: 0.5672\n","\n","Epoch 76: Learning rate is 0.000078\n","Epoch 76/150\n","\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.5720 - val_loss: 0.5734\n","\n","Epoch 77: Learning rate is 0.000078\n","Epoch 77/150\n","\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.5656 - val_loss: 0.5677\n","\n","Epoch 78: Learning rate is 0.000078\n","Epoch 78/150\n","\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.5757 - val_loss: 0.5721\n","\n","Epoch 79: Learning rate is 0.000078\n","Epoch 79/150\n","\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.5817 - val_loss: 0.5731\n","\n","Epoch 80: Learning rate is 0.000078\n","Epoch 80/150\n","\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.5877 - val_loss: 0.5603\n","\n","Epoch 81: Learning rate is 0.000039\n","Epoch 81/150\n","\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.5684 - val_loss: 0.5760\n","\n","Epoch 82: Learning rate is 0.000039\n","Epoch 82/150\n","\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.5728 - val_loss: 0.5732\n","\n","Epoch 83: Learning rate is 0.000039\n","Epoch 83/150\n","\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.5745 - val_loss: 0.5699\n","\n","Epoch 84: Learning rate is 0.000039\n","Epoch 84/150\n","\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.5784 - val_loss: 0.5764\n","\n","Epoch 85: Learning rate is 0.000039\n","Epoch 85/150\n","\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.5669 - val_loss: 0.5645\n","\n","Epoch 86: Learning rate is 0.000039\n","Epoch 86/150\n","\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.5820 - val_loss: 0.5723\n","\n","Epoch 87: Learning rate is 0.000039\n","Epoch 87/150\n","\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.5776 - val_loss: 0.5707\n","\n","Epoch 88: Learning rate is 0.000039\n","Epoch 88/150\n","\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.5831 - val_loss: 0.5622\n","\n","Epoch 89: Learning rate is 0.000039\n","Epoch 89/150\n","\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.5778 - val_loss: 0.5784\n","\n","Epoch 90: Learning rate is 0.000039\n","Epoch 90/150\n","\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.5899 - val_loss: 0.5800\n","\n","Epoch 91: Learning rate is 0.000020\n","Epoch 91/150\n","\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.5838 - val_loss: 0.5715\n","\n","Epoch 92: Learning rate is 0.000020\n","Epoch 92/150\n","\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.5909 - val_loss: 0.5623\n","\n","Epoch 93: Learning rate is 0.000020\n","Epoch 93/150\n","\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.5797 - val_loss: 0.5667\n","\n","Epoch 94: Learning rate is 0.000020\n","Epoch 94/150\n","\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.5789 - val_loss: 0.5617\n","\n","Epoch 95: Learning rate is 0.000020\n","Epoch 95/150\n","\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.5718 - val_loss: 0.5595\n","\n","Epoch 96: Learning rate is 0.000020\n","Epoch 96/150\n","\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.5771 - val_loss: 0.5652\n","\n","Epoch 97: Learning rate is 0.000020\n","Epoch 97/150\n","\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.5725 - val_loss: 0.5761\n","\n","Epoch 98: Learning rate is 0.000020\n","Epoch 98/150\n","\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.5768 - val_loss: 0.5557\n","\n","Epoch 99: Learning rate is 0.000020\n","Epoch 99/150\n","\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.5792 - val_loss: 0.5659\n","\n","Epoch 100: Learning rate is 0.000020\n","Epoch 100/150\n","\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.5789 - val_loss: 0.5788\n","\n","Epoch 101: Learning rate is 0.000010\n","Epoch 101/150\n","\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.5801 - val_loss: 0.5605\n","\n","Epoch 102: Learning rate is 0.000010\n","Epoch 102/150\n","\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.5782 - val_loss: 0.5758\n","\n","Epoch 103: Learning rate is 0.000010\n","Epoch 103/150\n","\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.5715 - val_loss: 0.5580\n","\n","Epoch 104: Learning rate is 0.000010\n","Epoch 104/150\n","\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.5755 - val_loss: 0.5582\n","\n","Epoch 105: Learning rate is 0.000010\n","Epoch 105/150\n","\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.5673 - val_loss: 0.5599\n","\n","Epoch 106: Learning rate is 0.000010\n","Epoch 106/150\n","\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.5679 - val_loss: 0.5511\n","\n","Epoch 107: Learning rate is 0.000010\n","Epoch 107/150\n","\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.5715 - val_loss: 0.5655\n","\n","Epoch 108: Learning rate is 0.000010\n","Epoch 108/150\n","\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.5784 - val_loss: 0.5606\n","\n","Epoch 109: Learning rate is 0.000010\n","Epoch 109/150\n","\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.5721 - val_loss: 0.5634\n","\n","Epoch 110: Learning rate is 0.000010\n","Epoch 110/150\n","\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.5726 - val_loss: 0.5535\n","\n","Epoch 111: Learning rate is 0.000005\n","Epoch 111/150\n","\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.5684 - val_loss: 0.5621\n","\n","Epoch 112: Learning rate is 0.000005\n","Epoch 112/150\n","\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.5783 - val_loss: 0.5571\n","\n","Epoch 113: Learning rate is 0.000005\n","Epoch 113/150\n","\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.5618 - val_loss: 0.5588\n","\n","Epoch 114: Learning rate is 0.000005\n","Epoch 114/150\n","\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.5556 - val_loss: 0.5567\n","\n","Epoch 115: Learning rate is 0.000005\n","Epoch 115/150\n","\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.5616 - val_loss: 0.5499\n","\n","Epoch 116: Learning rate is 0.000005\n","Epoch 116/150\n","\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.5692 - val_loss: 0.5806\n","\n","Epoch 117: Learning rate is 0.000005\n","Epoch 117/150\n","\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.5615 - val_loss: 0.5536\n","\n","Epoch 118: Learning rate is 0.000005\n","Epoch 118/150\n","\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.5697 - val_loss: 0.5507\n","\n","Epoch 119: Learning rate is 0.000005\n","Epoch 119/150\n","\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.5609 - val_loss: 0.5455\n","\n","Epoch 120: Learning rate is 0.000005\n","Epoch 120/150\n","\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.5520 - val_loss: 0.5516\n","\n","Epoch 121: Learning rate is 0.000002\n","Epoch 121/150\n","\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.5530 - val_loss: 0.5524\n","\n","Epoch 122: Learning rate is 0.000002\n","Epoch 122/150\n","\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.5602 - val_loss: 0.5478\n","\n","Epoch 123: Learning rate is 0.000002\n","Epoch 123/150\n","\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.5581 - val_loss: 0.5540\n","\n","Epoch 124: Learning rate is 0.000002\n","Epoch 124/150\n","\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.5697 - val_loss: 0.5447\n","\n","Epoch 125: Learning rate is 0.000002\n","Epoch 125/150\n","\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.5497 - val_loss: 0.5443\n","\n","Epoch 126: Learning rate is 0.000002\n","Epoch 126/150\n","\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.5481 - val_loss: 0.5625\n","\n","Epoch 127: Learning rate is 0.000002\n","Epoch 127/150\n","\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.5455 - val_loss: 0.5492\n","\n","Epoch 128: Learning rate is 0.000002\n","Epoch 128/150\n","\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.5571 - val_loss: 0.5402\n","\n","Epoch 129: Learning rate is 0.000002\n","Epoch 129/150\n","\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.5577 - val_loss: 0.5469\n","\n","Epoch 130: Learning rate is 0.000002\n","Epoch 130/150\n","\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.5579 - val_loss: 0.5512\n","\n","Epoch 131: Learning rate is 0.000001\n","Epoch 131/150\n","\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.5563 - val_loss: 0.5542\n","\n","Epoch 132: Learning rate is 0.000001\n","Epoch 132/150\n","\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.5613 - val_loss: 0.5529\n","\n","Epoch 133: Learning rate is 0.000001\n","Epoch 133/150\n","\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.5574 - val_loss: 0.5423\n","\n","Epoch 134: Learning rate is 0.000001\n","Epoch 134/150\n","\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.5629 - val_loss: 0.5458\n","\n","Epoch 135: Learning rate is 0.000001\n","Epoch 135/150\n","\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.5650 - val_loss: 0.5417\n","\n","Epoch 136: Learning rate is 0.000001\n","Epoch 136/150\n","\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.5539 - val_loss: 0.5419\n","\n","Epoch 137: Learning rate is 0.000001\n","Epoch 137/150\n","\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.5595 - val_loss: 0.5366\n","\n","Epoch 138: Learning rate is 0.000001\n","Epoch 138/150\n","\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.5499 - val_loss: 0.5387\n","\n","Epoch 139: Learning rate is 0.000001\n","Epoch 139/150\n","\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.5589 - val_loss: 0.5381\n","\n","Epoch 140: Learning rate is 0.000001\n","Epoch 140/150\n","\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.5577 - val_loss: 0.5478\n","\n","Epoch 141: Learning rate is 0.000001\n","Epoch 141/150\n","\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.5592 - val_loss: 0.5346\n","\n","Epoch 142: Learning rate is 0.000001\n","Epoch 142/150\n","\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.5503 - val_loss: 0.5324\n","\n","Epoch 143: Learning rate is 0.000001\n","Epoch 143/150\n","\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.5454 - val_loss: 0.5330\n","\n","Epoch 144: Learning rate is 0.000001\n","Epoch 144/150\n","\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.5469 - val_loss: 0.5367\n","\n","Epoch 145: Learning rate is 0.000001\n","Epoch 145/150\n","\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.5508 - val_loss: 0.5565\n","\n","Epoch 146: Learning rate is 0.000001\n","Epoch 146/150\n","\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.5504 - val_loss: 0.5409\n","\n","Epoch 147: Learning rate is 0.000001\n","Epoch 147/150\n","\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.5585 - val_loss: 0.5431\n","\n","Epoch 148: Learning rate is 0.000001\n","Epoch 148/150\n","\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.5466 - val_loss: 0.5351\n","\n","Epoch 149: Learning rate is 0.000001\n","Epoch 149/150\n","\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.5558 - val_loss: 0.5338\n","\n","Epoch 150: Learning rate is 0.000001\n","Epoch 150/150\n","\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.5456 - val_loss: 0.5374\n","Test Loss: 0.5919186472892761\n"]}]},{"cell_type":"markdown","source":["# 2. Feature Importance"],"metadata":{"id":"ellsdGiA53aq"}},{"cell_type":"code","source":["def accuracy(y_pred):\n","    return np.mean((y_pred > 0.5) == y_test)\n","\n","y_pred = model.predict(X_test, verbose=0).flatten()\n","print(f\"Accuracy: {accuracy(y_pred) * 100:.2f}%\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jDfthFw73d0M","executionInfo":{"status":"ok","timestamp":1733044975228,"user_tz":360,"elapsed":5,"user":{"displayName":"William Zhang","userId":"06004962365031563065"}},"outputId":"c8851d34-6f26-4bc0-b273-e49df5c4f61a"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 67.72%\n"]}]},{"cell_type":"code","source":["def model_0000():\n","    return model.predict(X_test, verbose=0).mean()\n","\n","def model_1000(x):\n","    tempx = pd.Series(x, index=X_test.index, dtype=float, name=\"Subject\")\n","    syntheticdata = pd.concat([tempx, X_test[[\"Course Title\", \"Sched Type\", \"Primary Instructor\"]]],axis=\"columns\")\n","    return model.predict(syntheticdata, verbose=0).mean()\n","\n","def model_0100(y):\n","    tempy = pd.Series(y, index=X_test.index, dtype=float, name=\"Course Title\")\n","    syntheticdata = pd.concat([X_test[[\"Subject\"]], tempy, X_test[[\"Sched Type\", \"Primary Instructor\"]]],axis=\"columns\")\n","    return model.predict(syntheticdata, verbose=0).mean()\n","\n","def model_0010(z):\n","    tempz = pd.Series(z, index=X_test.index, dtype=float, name=\"Sched Type\")\n","    syntheticdata = pd.concat([X_test[[\"Subject\", \"Course Title\"]], tempz, X_test[[\"Primary Instructor\"]]],axis=\"columns\")\n","    return model.predict(syntheticdata, verbose=0).mean()\n","\n","def model_0001(w):\n","    tempw = pd.Series(w, index=X_test.index, dtype=float, name=\"Primary Instructor\")\n","    syntheticdata = pd.concat([X_test[[\"Subject\", \"Course Title\", \"Sched Type\"]], tempw],axis=\"columns\")\n","    return model.predict(syntheticdata, verbose=0).mean()\n","\n","def model_1100(x, y):\n","    tempx = pd.Series(x, index=X_test.index, dtype=float, name=\"Subject\")\n","    tempy = pd.Series(y, index=X_test.index, dtype=float, name=\"Course Title\")\n","    syntheticdata = pd.concat([tempx, tempy, X_test[[\"Sched Type\", \"Primary Instructor\"]]],axis=\"columns\")\n","    return model.predict(syntheticdata, verbose=0).mean()\n","\n","def model_1010(x, z):\n","    tempx = pd.Series(x, index=X_test.index, dtype=float, name=\"Subject\")\n","    tempz = pd.Series(z, index=X_test.index, dtype=float, name=\"Sched Type\")\n","    syntheticdata = pd.concat([tempx, X_test[[\"Course Title\"]], tempz, X_test[[\"Primary Instructor\"]]],axis=\"columns\")\n","    return model.predict(syntheticdata, verbose=0).mean()\n","\n","def model_1001(x, w):\n","    tempx = pd.Series(x, index=X_test.index, dtype=float, name=\"Subject\")\n","    tempw = pd.Series(w, index=X_test.index, dtype=float, name=\"Primary Instructor\")\n","    syntheticdata = pd.concat([tempx, X_test[[\"Course Title\", \"Sched Type\"]], tempw],axis=\"columns\")\n","    return model.predict(syntheticdata, verbose=0).mean()\n","\n","def model_0110(y, z):\n","    tempy = pd.Series(y, index=X_test.index, dtype=float, name=\"Course Title\")\n","    tempz = pd.Series(z, index=X_test.index, dtype=float, name=\"Sched Type\")\n","    syntheticdata = pd.concat([X_test[[\"Subject\"]], tempy, tempz, X_test[[\"Primary Instructor\"]]],axis=\"columns\")\n","    return model.predict(syntheticdata, verbose=0).mean()\n","\n","def model_0101(y, w):\n","    tempy = pd.Series(y, index=X_test.index, dtype=float, name=\"Course Title\")\n","    tempw = pd.Series(w, index=X_test.index, dtype=float, name=\"Primary Instructor\")\n","    syntheticdata = pd.concat([X_test[[\"Subject\"]], tempy, X_test[[\"Sched Type\"]], tempw],axis=\"columns\")\n","    return model.predict(syntheticdata, verbose=0).mean()\n","\n","def model_0011(z, w):\n","    tempz = pd.Series(z, index=X_test.index, dtype=float, name=\"Sched Type\")\n","    tempw = pd.Series(w, index=X_test.index, dtype=float, name=\"Primary Instructor\")\n","    syntheticdata = pd.concat([X_test[[\"Subject\", \"Course Title\"]], tempz, tempw],axis=\"columns\")\n","    return model.predict(syntheticdata, verbose=0).mean()\n","\n","def model_1110(x, y, z):\n","    tempx = pd.Series(x, index=X_test.index, dtype=float, name=\"Subject\")\n","    tempy = pd.Series(y, index=X_test.index, dtype=float, name=\"Course Title\")\n","    tempz = pd.Series(z, index=X_test.index, dtype=float, name=\"Sched Type\")\n","    syntheticdata = pd.concat([tempx, tempy, tempz, X_test[[\"Primary Instructor\"]]],axis=\"columns\")\n","    return model.predict(syntheticdata, verbose=0).mean()\n","\n","def model_1101(x, y, w):\n","    tempx = pd.Series(x, index=X_test.index, dtype=float, name=\"Subject\")\n","    tempy = pd.Series(y, index=X_test.index, dtype=float, name=\"Course Title\")\n","    tempw = pd.Series(w, index=X_test.index, dtype=float, name=\"Primary Instructor\")\n","    syntheticdata = pd.concat([tempx, tempy, X_test[[\"Sched Type\"]], tempw],axis=\"columns\")\n","    return model.predict(syntheticdata, verbose=0).mean()\n","\n","def model_1011(x, z, w):\n","    tempx = pd.Series(x, index=X_test.index, dtype=float, name=\"Subject\")\n","    tempz = pd.Series(z, index=X_test.index, dtype=float, name=\"Sched Type\")\n","    tempw = pd.Series(w, index=X_test.index, dtype=float, name=\"Primary Instructor\")\n","    syntheticdata = pd.concat([tempx, X_test[[\"Course Title\"]], tempz, tempw],axis=\"columns\")\n","    return model.predict(syntheticdata, verbose=0).mean()\n","\n","def model_0111(y, z, w):\n","    tempy = pd.Series(y, index=X_test.index, dtype=float, name=\"Course Title\")\n","    tempz = pd.Series(z, index=X_test.index, dtype=float, name=\"Sched Type\")\n","    tempw = pd.Series(w, index=X_test.index, dtype=float, name=\"Primary Instructor\")\n","    syntheticdata = pd.concat([X_test[[\"Subject\"]], tempy, tempz, tempw],axis=\"columns\")\n","    return model.predict(syntheticdata, verbose=0).mean()\n","\n","def model_1111(x, y, z, w):\n","    tempx = pd.Series(x, index=X_test.index, dtype=float, name=\"Subject\")\n","    tempy = pd.Series(y, index=X_test.index, dtype=float, name=\"Course Title\")\n","    tempz = pd.Series(z, index=X_test.index, dtype=float, name=\"Sched Type\")\n","    tempw = pd.Series(w, index=X_test.index, dtype=float, name=\"Primary Instructor\")\n","    syntheticdata = pd.concat([tempx, tempy, tempz, tempw],axis=\"columns\")\n","    return model.predict(syntheticdata, verbose=0).mean()"],"metadata":{"id":"lnEs0zJzMXo8","executionInfo":{"status":"ok","timestamp":1733044975229,"user_tz":360,"elapsed":4,"user":{"displayName":"William Zhang","userId":"06004962365031563065"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["def A(m):\n","    return (y_test == (m.to_numpy() > 0.5)).mean()\n","\n","Accmodel_0000 = np.abs(model_0000() - y_test).mean()\n","Accmodel_1000 = A(X_test[[\"Subject\"]].apply(lambda row: model_1000(*row), axis=1))\n","Accmodel_0100 = A(X_test[[\"Course Title\"]].apply(lambda row: model_0100(*row), axis=1))\n","Accmodel_0010 = A(X_test[[\"Sched Type\"]].apply(lambda row: model_0010(*row), axis=1))\n","Accmodel_0001 = A(X_test[[\"Primary Instructor\"]].apply(lambda row: model_0001(*row), axis=1))\n","Accmodel_1100 = A(X_test[[\"Subject\", \"Course Title\"]].apply(lambda row: model_1100(*row), axis=1))\n","Accmodel_1010 = A(X_test[[\"Subject\", \"Sched Type\"]].apply(lambda row: model_1010(*row), axis=1))\n","Accmodel_1001 = A(X_test[[\"Subject\", \"Primary Instructor\"]].apply(lambda row: model_1001(*row), axis=1))\n","Accmodel_0110 = A(X_test[[\"Course Title\", \"Sched Type\"]].apply(lambda row: model_0110(*row), axis=1))\n","Accmodel_0101 = A(X_test[[\"Course Title\", \"Primary Instructor\"]].apply(lambda row: model_0101(*row), axis=1))\n","Accmodel_0011 = A(X_test[[\"Sched Type\", \"Primary Instructor\"]].apply(lambda row: model_0011(*row), axis=1))\n","Accmodel_1110 = A(X_test[[\"Subject\", \"Course Title\", \"Sched Type\"]].apply(lambda row: model_1110(*row), axis=1))\n","Accmodel_1101 = A(X_test[[\"Subject\", \"Course Title\", \"Primary Instructor\"]].apply(lambda row: model_1101(*row), axis=1))\n","Accmodel_1011 = A(X_test[[\"Subject\", \"Sched Type\", \"Primary Instructor\"]].apply(lambda row: model_1011(*row), axis=1))\n","Accmodel_0111 = A(X_test[[\"Course Title\", \"Sched Type\", \"Primary Instructor\"]].apply(lambda row: model_0111(*row), axis=1))\n","Accmodel_1111 = A(X_test[[\"Subject\", \"Course Title\", \"Sched Type\", \"Primary Instructor\"]].apply(lambda row: model_1111(*row), axis=1))"],"metadata":{"id":"Y4HpyXo2NnPq","executionInfo":{"status":"ok","timestamp":1733045466073,"user_tz":360,"elapsed":490848,"user":{"displayName":"William Zhang","userId":"06004962365031563065"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["from math import comb\n","\n","S_subject = 1/4 * (\n","    (Accmodel_1111 - Accmodel_0111) / comb(3, 3) +\n","    (Accmodel_1110 - Accmodel_0110) / comb(3, 2) +\n","    (Accmodel_1101 - Accmodel_0101) / comb(3, 2) +\n","    (Accmodel_1011 - Accmodel_0011) / comb(3, 2) +\n","    (Accmodel_1100 - Accmodel_0100) / comb(3, 1) +\n","    (Accmodel_1010 - Accmodel_0010) / comb(3, 1) +\n","    (Accmodel_1001 - Accmodel_0001) / comb(3, 1) +\n","    (Accmodel_1000 - Accmodel_0000) / comb(3, 0)\n",")\n","\n","S_course_title = 1/4 * (\n","    (Accmodel_1111 - Accmodel_1011) / comb(3, 3) +\n","    (Accmodel_1110 - Accmodel_1010) / comb(3, 2) +\n","    (Accmodel_1101 - Accmodel_1001) / comb(3, 2) +\n","    (Accmodel_0111 - Accmodel_0011) / comb(3, 2) +\n","    (Accmodel_1100 - Accmodel_1000) / comb(3, 1) +\n","    (Accmodel_0110 - Accmodel_0010) / comb(3, 1) +\n","    (Accmodel_0101 - Accmodel_0001) / comb(3, 1) +\n","    (Accmodel_0100 - Accmodel_0000) / comb(3, 0)\n",")\n","\n","S_sched_type = 1/4 * (\n","    (Accmodel_1111 - Accmodel_1101) / comb(3, 3) +\n","    (Accmodel_1110 - Accmodel_1100) / comb(3, 2) +\n","    (Accmodel_1011 - Accmodel_1001) / comb(3, 2) +\n","    (Accmodel_0111 - Accmodel_0101) / comb(3, 2) +\n","    (Accmodel_1010 - Accmodel_1000) / comb(3, 1) +\n","    (Accmodel_0110 - Accmodel_0100) / comb(3, 1) +\n","    (Accmodel_0011 - Accmodel_0001) / comb(3, 1) +\n","    (Accmodel_0010 - Accmodel_0000) / comb(3, 0)\n",")\n","\n","S_primary_instructor = 1/4 * (\n","    (Accmodel_1111 - Accmodel_1110) / comb(3, 3) +\n","    (Accmodel_1101 - Accmodel_1100) / comb(3, 2) +\n","    (Accmodel_1011 - Accmodel_1010) / comb(3, 2) +\n","    (Accmodel_0111 - Accmodel_0110) / comb(3, 2) +\n","    (Accmodel_1001 - Accmodel_1000) / comb(3, 1) +\n","    (Accmodel_0101 - Accmodel_0100) / comb(3, 1) +\n","    (Accmodel_0011 - Accmodel_0010) / comb(3, 1) +\n","    (Accmodel_0001 - Accmodel_0000) / comb(3, 0)\n",")\n","\n","text=[]\n","text.append(r\"$S_{{\\text{{Subject}}}}={:.4f}$\".format(S_subject))\n","text.append(r\"$S_{{\\text{{Course Title}}}}={:.4f}$\".format(S_course_title))\n","text.append(r\"$S_{{\\text{{Sched Type}}}}={:.4f}$\".format(S_sched_type))\n","text.append(r\"$S_{{\\text{{Primary Instructor}}}}={:.4f}$\".format(S_primary_instructor))\n","textbox(text)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":278},"id":"_MOdXSseg6O2","executionInfo":{"status":"ok","timestamp":1733045466219,"user_tz":360,"elapsed":149,"user":{"displayName":"William Zhang","userId":"06004962365031563065"}},"outputId":"f9126851-2c21-48de-b948-174af84b5648"},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 100x100 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"markdown","source":["We see from the above that schedule type seems to have the highest importance, followed by subject, followed by course title, then primary instructor, though the importance overall is very small, suggesting that there is not much relation between the input features and the output."],"metadata":{"id":"7LBhahGTg78v"}}]}